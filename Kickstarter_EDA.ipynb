{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "icYGYXF4PoZp",
    "outputId": "47cb2af6-3cab-489a-9b7c-32534cf54eb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe dataset can be found here:\\nhttps://webrobots.io/kickstarter-datasets/\\nhttps://s3.amazonaws.com/weruns/forfun/Kickstarter/Kickstarter_2021-06-17T03_20_03_179Z.zip\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "# from google.colab import files\n",
    "# import io \n",
    "import re\n",
    "import datetime\n",
    "import ast\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Kickstarter.csv\")\n",
    "\n",
    "\"\"\"\n",
    "The dataset can be found here:\n",
    "https://webrobots.io/kickstarter-datasets/\n",
    "https://s3.amazonaws.com/weruns/forfun/Kickstarter/Kickstarter_2021-06-17T03_20_03_179Z.zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QHXaTLJbZXZs"
   },
   "outputs": [],
   "source": [
    "# df = df.drop(columns=[\"currency_symbol\",\n",
    "#                  \"country_displayable_name\",\n",
    "#                  \"created_at\",\n",
    "#                  \"creator\",\n",
    "#                  \"country\",\n",
    "#                  \"urls\",\n",
    "#                  \"currency_trailing_code\",\n",
    "#                  \"friends\",\n",
    "#                  \"fx_rate\",\n",
    "#                  \"id\",\n",
    "#                  \"is_starred\",\n",
    "#                  \"name\",\n",
    "#                  \"permissions\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "QITHKpKBUZ1b",
    "outputId": "dcd937fa-d879-4e99-d0b4-30dc8fcda1dd"
   },
   "outputs": [],
   "source": [
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTVsN6ZQViwt"
   },
   "source": [
    "Do we want to combine find the length of the campaign from (created at and deadline) to see if there is value there. \n",
    "\n",
    "keep location, clean and ckeep city name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Yu1Y5CaQSpJ8"
   },
   "outputs": [],
   "source": [
    "# def clean_data(text):\n",
    "#     email_regex = r\"\\S*@\\S*\\s?\"\n",
    "#     non_alpha = \"[^a-zA-Z0-9 ]\"\n",
    "#     multi_white_spaces = \"[ ]{2,}\"\n",
    "#     text = re.sub(email_regex, \"\", text)\n",
    "#     text = re.sub(non_alpha, \"\", text)\n",
    "#     text = re.sub(multi_white_spaces, \"\", text)\n",
    "#     return text.lower().lstrip().rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjRPDmIsQB-M"
   },
   "source": [
    "# Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TzIPTv0nQD4G"
   },
   "outputs": [],
   "source": [
    "# file_path = 'Downloads/Kickstarter_2021-06-17T03_20_03_179Z/Kickstarter001.csv'\n",
    "file_path = \"Kickstarter.csv\"\n",
    "# file_path_small_test = 'small_file.csv'\n",
    "\n",
    "\n",
    "def clean_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    def change_to_time_series(item):\n",
    "        item = datetime.datetime.fromtimestamp(item)\n",
    "        return item\n",
    "    \n",
    "    # change the 'created-at', 'deadline', 'state_changed_at' columns\n",
    "    # to time series columns\n",
    "    time_series_columns = ['created_at', 'deadline', 'state_changed_at', 'launched_at']\n",
    "    for column in time_series_columns:\n",
    "        df[column] = df[column].apply(change_to_time_series)\n",
    "    \n",
    "    # dropping columns with all null values\n",
    "    # for reference these the column names:\n",
    "    # ['friends', 'is_backing', 'is_starred', 'permissions']\n",
    "    all_null_columns = df.isnull().sum() == len(df)\n",
    "#     to_drop = all_null_columns[all_null_columns == True].index\n",
    "    to_drop = ['friends', 'is_backing', 'is_starred', 'permissions']\n",
    "    df = df.drop(columns=to_drop, axis=1)\n",
    "    \n",
    "    df = df.drop(columns=[\"currency_symbol\",\n",
    "                          \"country_displayable_name\",\n",
    "                          \"creator\",\n",
    "                          \"country\",\n",
    "                          \"urls\",\n",
    "                          \"source_url\",\n",
    "                          \"currency_trailing_code\",\n",
    "                          \"fx_rate\",\n",
    "                          \"id\",\n",
    "                          \"name\",\n",
    "                          \"disable_communication\",\n",
    "                          \"photo\", # has url for photos might be useful later \n",
    "                          \"usd_type\", \n",
    "                          'converted_pledged_amount',\n",
    "                          'pledged',\n",
    "                          'usd_exchange_rate',\n",
    "                          'static_usd_rate',\n",
    "                          'currency', # dropping due to have pledged in USD\n",
    "                          'current_currency'  # dropping due to have pledged in USD\n",
    "                         ], axis=1)\n",
    "    \n",
    "    def extract_dictionary_info(item):\n",
    "        \"\"\" Use the apply method with the column name.\n",
    "        Takes in dictionary in string form,\n",
    "        converts it into a dictionary, and\n",
    "        returns info_type requested in a new column.\n",
    "        \"\"\"\n",
    "        my_dic = ast.literal_eval(item)\n",
    "        return my_dic\n",
    "\n",
    "    cat_df = df['category'].apply(extract_dictionary_info).apply(pd.Series)\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Dance')] = 'Dance'\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Photography')] = 'Photography'\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Games')] = 'Games'\n",
    "    \n",
    "    df['category_2'] = cat_df.parent_name    \n",
    "    # df = pd.concat([df,pd.get_dummies(df['category_2'], dtype = float)], axis=1)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[\"sub_categories\"] = le.fit_transform(df[\"category_2\"])\n",
    "    # 2 is Flim and Video \n",
    "    # 0 is Dance\n",
    "    # 3 is Games\n",
    "    # 1 is Fashion\n",
    "    df.drop(columns=['category', 'category_2'], inplace=True)\n",
    "      \n",
    "    \n",
    "    # location\n",
    "    df.dropna(inplace=True)\n",
    "    loc_df = df['location'].apply(json.loads).apply(pd.Series)\n",
    "    df['location_2'] = loc_df.country\n",
    "    df.drop(columns='location', inplace=True)\n",
    "    df[\"sub_location\"] = le.fit_transform(df[\"location_2\"])\n",
    "    # Need to find locations from the integer and add here\n",
    "    df.drop(columns=['location_2'], inplace=True)\n",
    "\n",
    "    \n",
    "    # columns I can't get to work\n",
    "    # in dictionary format need to work on OR text data\n",
    "    # text_data need to vectorize: 'blurb\n",
    "    drop_for_now = ['blurb', 'profile', 'slug']\n",
    "    df.drop(columns=drop_for_now, inplace=True)\n",
    "    \n",
    "    \n",
    "    # creating our target variable, we had the four sub-categories:\n",
    "    # successful, failed, canceled, live\n",
    "    # turn it into a binary variable\n",
    "    df['target'] = 0\n",
    "    df['target'].loc[df.state == 'successful'] = 1\n",
    "    df.drop(columns='state', inplace=True)\n",
    "    \n",
    "    # changing boolean to integers\n",
    "    df['spotlight_2'] = 0\n",
    "    df['spotlight_2'].loc[df.spotlight == True] = 1\n",
    "\n",
    "    df['staff_pick_2'] = 0\n",
    "    df['staff_pick_2'].loc[df.staff_pick == True] = 1\n",
    "\n",
    "    df['is_starrable_2'] = 0\n",
    "    df['is_starrable_2'].loc[df.is_starrable == True] = 1\n",
    "    df.drop(columns=['spotlight', 'staff_pick', 'is_starrable', \"spotlight_2\", \"backers_count\"],\n",
    "           inplace=True)\n",
    "\n",
    "\n",
    "    \n",
    "    # removing the launched_at and state_changed_at time series columns\n",
    "    # add at your discretion\n",
    "    time_series = ['created_at', 'deadline','state_changed_at', 'launched_at', \"usd_pledged\"] \n",
    "    # Drop USD pledged for leakage, duh \n",
    "    df.drop(columns=time_series, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "up6Gp1DNlSbf",
    "outputId": "3590996f-1970-4555-f070-557653e283f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sub_categories</th>\n",
       "      <th>sub_location</th>\n",
       "      <th>target</th>\n",
       "      <th>staff_pick_2</th>\n",
       "      <th>is_starrable_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      goal  sub_categories  sub_location  target  staff_pick_2  is_starrable_2\n",
       "0  15000.0               3             2       0             0               1\n",
       "1  10000.0               2            61       1             0               0\n",
       "2   3000.0               0            61       1             0               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the data and passing through the cleaning function\n",
    "df = clean_data(file_path)\n",
    "# df = clean_data(file_path_small_test)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4cw4lwL5ekV",
    "outputId": "8931abb1-0b73-4349-b3a0-4f36311f4a14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3660 entries, 0 to 3661\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   goal            3660 non-null   float64\n",
      " 1   sub_categories  3660 non-null   int64  \n",
      " 2   sub_location    3660 non-null   int64  \n",
      " 3   target          3660 non-null   int64  \n",
      " 4   staff_pick_2    3660 non-null   int64  \n",
      " 5   is_starrable_2  3660 non-null   int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 200.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF0vaA-RJv_f"
   },
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>sub_categories</th>\n",
       "      <th>sub_location</th>\n",
       "      <th>target</th>\n",
       "      <th>staff_pick_2</th>\n",
       "      <th>is_starrable_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>-0.015123</td>\n",
       "      <td>-0.056283</td>\n",
       "      <td>-0.010161</td>\n",
       "      <td>-0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_categories</th>\n",
       "      <td>0.022875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153201</td>\n",
       "      <td>-0.102882</td>\n",
       "      <td>-0.161327</td>\n",
       "      <td>0.290464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_location</th>\n",
       "      <td>-0.015123</td>\n",
       "      <td>-0.153201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.093118</td>\n",
       "      <td>-0.078789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.056283</td>\n",
       "      <td>-0.102882</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215084</td>\n",
       "      <td>-0.356840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff_pick_2</th>\n",
       "      <td>-0.010161</td>\n",
       "      <td>-0.161327</td>\n",
       "      <td>0.093118</td>\n",
       "      <td>0.215084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_starrable_2</th>\n",
       "      <td>-0.005657</td>\n",
       "      <td>0.290464</td>\n",
       "      <td>-0.078789</td>\n",
       "      <td>-0.356840</td>\n",
       "      <td>-0.058756</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    goal  sub_categories  sub_location    target  \\\n",
       "goal            1.000000        0.022875     -0.015123 -0.056283   \n",
       "sub_categories  0.022875        1.000000     -0.153201 -0.102882   \n",
       "sub_location   -0.015123       -0.153201      1.000000  0.136986   \n",
       "target         -0.056283       -0.102882      0.136986  1.000000   \n",
       "staff_pick_2   -0.010161       -0.161327      0.093118  0.215084   \n",
       "is_starrable_2 -0.005657        0.290464     -0.078789 -0.356840   \n",
       "\n",
       "                staff_pick_2  is_starrable_2  \n",
       "goal               -0.010161       -0.005657  \n",
       "sub_categories     -0.161327        0.290464  \n",
       "sub_location        0.093118       -0.078789  \n",
       "target              0.215084       -0.356840  \n",
       "staff_pick_2        1.000000       -0.058756  \n",
       "is_starrable_2     -0.058756        1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7UmTtGbxg08v"
   },
   "outputs": [],
   "source": [
    "# Split the data to avoid leakage\n",
    "x = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyOxMKfPhKMP",
    "outputId": "3ed5e817-7aa6-4b67-a621-e97a2eef56e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 3294\n",
      "x_val: 366\n",
      "y_train: (3294,)\n",
      "y_val: (366,)\n"
     ]
    }
   ],
   "source": [
    "# Create a training and validation set\n",
    "# Smaller test size is acceptable due to the amount of data available\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=.1, random_state=42)\n",
    "\n",
    "print('x_train:', len(X_train))\n",
    "print('x_val:', len(X_val))\n",
    "print('y_train:',y_train.shape)\n",
    "print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Model Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for our dataset is: 0.6900425015179114\n"
     ]
    }
   ],
   "source": [
    "baseline = y_train.value_counts(normalize = True).max()\n",
    "print(\"The baseline score for our dataset is:\", baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nig3MQQ50lq"
   },
   "source": [
    "# Explore Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xVyAyWdY6eXN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, ReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# required for compatibility bewteen sklearn and keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure a Neural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a3dwFJZ-6Hp2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input dimensions to avoid hidden layer issues\n",
    "input_dims = X_train.shape[1]\n",
    "input_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cl3S1NVq8gQo"
   },
   "source": [
    "## Create Model Function ##\n",
    "This function should help you save time on creating more models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fLuqTrOY7zce"
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(units = 128, optimizer = \"adam\", activation = \"sigmoid\"):\n",
    "    \"\"\"\"\n",
    "    Returns a complied keras model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units: int \n",
    "        number of neruons/nodes/units to use in each hidden layer\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model: keras object \n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 64, input_dim = input_dims, activation = activation))\n",
    "    model.add(Dense(units = 32, activation = activation))\n",
    "    model.add(Dense(units = 10, activation = activation))   \n",
    "    model.add(Dense(1, activation=\"sigmoid\")) # USE SIGMOID FOR BINARY CLASSIFICATION\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer = \"adam\",\n",
    "                    metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d0QkGvHp5ghF"
   },
   "outputs": [],
   "source": [
    "# Instantiate a base model for grid search\n",
    "base_model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZUrJjdY9h5f"
   },
   "source": [
    "### Perform a Grid Search To Optimize Our Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vJ8zWJoB7PA9"
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [32],\n",
    "              'epochs': [3],\n",
    "              'units':[32, 64]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dzihfCv-IRC",
    "outputId": "b98811cf-61b4-4dc2-80d8-4521bb3658d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/3\n",
      "103/103 [==============================] - 1s 2ms/step - loss: 0.6776 - accuracy: 0.5835\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6900\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6900\n",
      "Best: 0.6900424957275391 using {'batch_size': 32, 'epochs': 3, 'units': 32}\n",
      "Means: 0.6900424957275391, Stdev: 0.010312853587184763 with: {'batch_size': 32, 'epochs': 3, 'units': 32}\n",
      "Means: 0.6900424957275391, Stdev: 0.010312853587184763 with: {'batch_size': 32, 'epochs': 3, 'units': 64}\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator = base_model,\n",
    "                    param_grid = param_grid, \n",
    "                    n_jobs=-2, \n",
    "                    verbose=1, \n",
    "                    cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8gyYa85EZJe",
    "outputId": "f8515294-13cc-4c34-aa77-ba9f5a740c86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 3,\n",
       " 'units': 32,\n",
       " 'build_fn': <function __main__.create_model(units=128, optimizer='adam', activation='sigmoid')>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the best model \n",
    "best_nn_model = grid_result.best_estimator_\n",
    "# Confirm the models params\n",
    "best_nn_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "103/103 - 1s - loss: 0.6205 - accuracy: 0.6900 - val_loss: 0.6000 - val_accuracy: 0.7131\n",
      "Epoch 2/3\n",
      "103/103 - 0s - loss: 0.6199 - accuracy: 0.6900 - val_loss: 0.6008 - val_accuracy: 0.7131\n",
      "Epoch 3/3\n",
      "103/103 - 0s - loss: 0.6198 - accuracy: 0.6900 - val_loss: 0.6026 - val_accuracy: 0.7131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1531bf280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    best_nn_model.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data = (X_val,y_val),\n",
    "                        verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.7131\n",
      "The best NN model validation score is: 0.7131147384643555\n"
     ]
    }
   ],
   "source": [
    "best_nn_model_val_score = best_nn_model.score(X_val,y_val)\n",
    "print(\"The best NN model validation score is:\", best_nn_model_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Classifier Model \n",
    "Compare this model with our NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('randomforestclassifier',\n",
       "                 RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = make_pipeline(\n",
    "                        RandomForestClassifier(\n",
    "                                                random_state= 42,\n",
    "                                                ))\n",
    "\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the CLF models score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CLF model validation score is: 0.7896174863387978\n"
     ]
    }
   ],
   "source": [
    "clf_model_val_score = clf_model.score(X_val,y_val)\n",
    "print(\"The best CLF model validation score is:\", clf_model_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_fit_params',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_final_estimator',\n",
       " '_fit',\n",
       " '_get_param_names',\n",
       " '_get_params',\n",
       " '_get_tags',\n",
       " '_inverse_transform',\n",
       " '_iter',\n",
       " '_log_message',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_replace_estimator',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_params',\n",
       " '_sk_visual_block_',\n",
       " '_transform',\n",
       " '_validate_data',\n",
       " '_validate_names',\n",
       " '_validate_steps',\n",
       " 'classes_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'fit_predict',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'memory',\n",
       " 'n_features_in_',\n",
       " 'named_steps',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_params',\n",
       " 'steps',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(clf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_h5_model.h5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf_model, \"my_h5_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko0g_byzFtVW",
    "outputId": "35da2382-7851-4ada-96f2-98d6744dacb0"
   },
   "outputs": [],
   "source": [
    "# # Save the entire model as a SavedModel.\n",
    "# !mkdir -p saved_model\n",
    "# clf_model.save('my_h5_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kickstarter EDA.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b6aa737f36c5d93b6cbe8b742cd1c1391a187201e6ed0bc134578f07fcbe3de9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
