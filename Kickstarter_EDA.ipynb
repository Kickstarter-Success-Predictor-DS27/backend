{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install catboost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import sys\r\n",
    "# from google.colab import files\r\n",
    "# import io \r\n",
    "import re\r\n",
    "import datetime\r\n",
    "import ast\r\n",
    "import json\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import preprocessing\r\n",
    "\r\n",
    "df = pd.read_csv(\"Kickstarter.csv\")\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "The dataset can be found here:\r\n",
    "https://webrobots.io/kickstarter-datasets/\r\n",
    "https://s3.amazonaws.com/weruns/forfun/Kickstarter/Kickstarter_2021-06-17T03_20_03_179Z.zip\r\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "icYGYXF4PoZp",
    "outputId": "47cb2af6-3cab-489a-9b7c-32534cf54eb8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load The Dataset"
   ],
   "metadata": {
    "id": "XjRPDmIsQB-M"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file_path = \"Kickstarter.csv\"\r\n",
    "\r\n",
    "\r\n",
    "def clean_data(file_path):\r\n",
    "    df = pd.read_csv(file_path)\r\n",
    "    \r\n",
    "    def change_to_time_series(item):\r\n",
    "        item = datetime.datetime.fromtimestamp(item)\r\n",
    "        return item\r\n",
    "    \r\n",
    "    # change the 'created-at', 'deadline', 'state_changed_at' columns\r\n",
    "    # to time series columns\r\n",
    "    time_series_columns = ['created_at', 'deadline', 'state_changed_at', 'launched_at']\r\n",
    "    for column in time_series_columns:\r\n",
    "        df[column] = df[column].apply(change_to_time_series)\r\n",
    "    \r\n",
    "    # dropping columns with all null values\r\n",
    "    all_null_columns = df.isnull().sum() == len(df)\r\n",
    "\r\n",
    "    to_drop = ['friends', 'is_backing', 'is_starred', 'permissions']\r\n",
    "    \r\n",
    "    df = df.drop(columns=to_drop, axis=1)\r\n",
    "    \r\n",
    "    df = df.drop(columns=[\"currency_symbol\",\r\n",
    "                          \"country_displayable_name\",\r\n",
    "                          \"creator\",\r\n",
    "                          \"country\",\r\n",
    "                          \"urls\",\r\n",
    "                          \"source_url\",\r\n",
    "                          \"currency_trailing_code\",\r\n",
    "                          \"fx_rate\",\r\n",
    "                          \"id\",\r\n",
    "                          \"name\",\r\n",
    "                          \"disable_communication\",\r\n",
    "                          \"photo\", # has url for photos might be useful later \r\n",
    "                          \"usd_type\", \r\n",
    "                          'converted_pledged_amount',\r\n",
    "                          'pledged',\r\n",
    "                          'usd_exchange_rate',\r\n",
    "                          'static_usd_rate',\r\n",
    "                          'currency', # dropping due to have pledged in USD\r\n",
    "                          'current_currency'  # dropping due to have pledged in USD\r\n",
    "                         ], axis=1)\r\n",
    "    \r\n",
    "    def extract_dictionary_info(item):\r\n",
    "        \"\"\" Use the apply method with the column name.\r\n",
    "        Takes in dictionary in string form,\r\n",
    "        converts it into a dictionary, and\r\n",
    "        returns info_type requested in a new column.\r\n",
    "        \"\"\"\r\n",
    "        my_dic = ast.literal_eval(item)\r\n",
    "        return my_dic\r\n",
    "\r\n",
    "    cat_df = df['category'].apply(extract_dictionary_info).apply(pd.Series)\r\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Dance')] = 'Dance'\r\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Photography')] = 'Photography'\r\n",
    "    cat_df['parent_name'].loc[(cat_df.parent_name.isnull() == True)& (cat_df['name'] == 'Games')] = 'Games'\r\n",
    "    \r\n",
    "    df['category_2'] = cat_df.parent_name    \r\n",
    "    \r\n",
    "    le = preprocessing.LabelEncoder()\r\n",
    "    df[\"sub_categories\"] = le.fit_transform(df[\"category_2\"])\r\n",
    "    # 2 is Flim and Video \r\n",
    "    # 0 is Dance\r\n",
    "    # 3 is Games\r\n",
    "    # 1 is Fashion\r\n",
    "    \r\n",
    "    df.drop(columns=['category', 'category_2'], inplace=True)\r\n",
    "      \r\n",
    "    \r\n",
    "    # location\r\n",
    "    df.dropna(inplace=True)\r\n",
    "    loc_df = df['location'].apply(json.loads).apply(pd.Series)\r\n",
    "    df['location_2'] = loc_df.country\r\n",
    "    df.drop(columns='location', inplace=True)\r\n",
    "    df[\"sub_location\"] = le.fit_transform(df[\"location_2\"])\r\n",
    "    # Need to find locations from the integer and add here\r\n",
    "    df.drop(columns=['location_2'], inplace=True)\r\n",
    "\r\n",
    "    \r\n",
    "    # in dictionary format need to work on OR text data\r\n",
    "    drop_for_now = ['blurb', 'profile', 'slug']\r\n",
    "    df.drop(columns=drop_for_now, inplace=True)\r\n",
    "    \r\n",
    "    \r\n",
    "    # creating our target variable, we had the four sub-categories:\r\n",
    "    # successful, failed, canceled, live\r\n",
    "    # turn it into a binary variable\r\n",
    "    df['target'] = 0\r\n",
    "    df['target'].loc[df.state == 'successful'] = 1\r\n",
    "    df.drop(columns='state', inplace=True)\r\n",
    "    \r\n",
    "    # changing boolean to integers\r\n",
    "    df['spotlight_2'] = 0\r\n",
    "    df['spotlight_2'].loc[df.spotlight == True] = 1\r\n",
    "\r\n",
    "    df['staff_pick_2'] = 0\r\n",
    "    df['staff_pick_2'].loc[df.staff_pick == True] = 1\r\n",
    "\r\n",
    "    df['is_starrable_2'] = 0\r\n",
    "    df['is_starrable_2'].loc[df.is_starrable == True] = 1\r\n",
    "    df.drop(columns=['spotlight', 'staff_pick', 'is_starrable', \"spotlight_2\", \"backers_count\"],\r\n",
    "           inplace=True)\r\n",
    "\r\n",
    "    # removing the launched_at and state_changed_at time series columns\r\n",
    "    # add at your discretion\r\n",
    "    time_series = ['created_at', 'deadline','state_changed_at', 'launched_at', \"usd_pledged\"] \r\n",
    "    # Drop USD pledged for leakage, duh \r\n",
    "    df.drop(columns=time_series, inplace=True)\r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {
    "id": "TzIPTv0nQD4G"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reading in the data and passing through the cleaning function\r\n",
    "df = clean_data(file_path)\r\n",
    "df.info()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "up6Gp1DNlSbf",
    "outputId": "3590996f-1970-4555-f070-557653e283f6",
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the Data"
   ],
   "metadata": {
    "id": "KF0vaA-RJv_f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split the data to avoid leakage\r\n",
    "x = df.drop(columns=['target'])\r\n",
    "y = df['target']"
   ],
   "outputs": [],
   "metadata": {
    "id": "7UmTtGbxg08v"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a training and validation set\r\n",
    "# Smaller test size is acceptable due to the amount of data available\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=.1, random_state=42)\r\n",
    "\r\n",
    "print('x_train:', len(X_train))\r\n",
    "print('x_val:', len(X_val))\r\n",
    "print('y_train:',y_train.shape)\r\n",
    "print('y_val:', y_val.shape)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyOxMKfPhKMP",
    "outputId": "3ed5e817-7aa6-4b67-a621-e97a2eef56e8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Model Baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "baseline = y_train.value_counts(normalize = True).max()\r\n",
    "print(\"The baseline score for our dataset is:\", baseline)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explore Models"
   ],
   "metadata": {
    "id": "_Nig3MQQ50lq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, ReLU\r\n",
    "from tensorflow.keras.callbacks import TensorBoard\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "\r\n",
    "# required for compatibility bewteen sklearn and keras\r\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ],
   "outputs": [],
   "metadata": {
    "id": "xVyAyWdY6eXN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure a Neural Network ##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define input dimensions to avoid hidden layer issues\r\n",
    "input_dims = X_train.shape[1]\r\n",
    "input_dims"
   ],
   "outputs": [],
   "metadata": {
    "id": "a3dwFJZ-6Hp2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Model Function ##\n",
    "This function should help you save time on creating more models."
   ],
   "metadata": {
    "id": "Cl3S1NVq8gQo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(units = 32, optimizer = \"adam\", activation = \"sigmoid\"):\r\n",
    "    \"\"\"\"\r\n",
    "    Returns a complied keras model \r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    units: int \r\n",
    "        number of neruons/nodes/units to use in each hidden layer\r\n",
    "        \r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    model: keras object \r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(units = 64, input_dim = input_dims, activation = activation))\r\n",
    "    model.add(Dense(units = 32, activation = activation))\r\n",
    "    model.add(Dense(units = 10, activation = activation))   \r\n",
    "    model.add(Dense(1, activation=\"sigmoid\")) # USE SIGMOID FOR BINARY CLASSIFICATION\r\n",
    "    model.compile(loss=\"binary_crossentropy\",\r\n",
    "                    optimizer = \"adam\",\r\n",
    "                    metrics=[\"accuracy\"])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "fLuqTrOY7zce"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instantiate a base model for grid search\r\n",
    "base_model = KerasClassifier(build_fn = create_model)"
   ],
   "outputs": [],
   "metadata": {
    "id": "d0QkGvHp5ghF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform a Grid Search To Optimize Our Model "
   ],
   "metadata": {
    "id": "8ZUrJjdY9h5f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define the grid search parameters\r\n",
    "param_grid = {'batch_size': [128, 64, 32],\r\n",
    "              'epochs': [25, 10 , 5],\r\n",
    "              'units':[128, 64, 32],\r\n",
    "              \"optimizer\": [\"sigmoid\", \"adam\", \"relu\"]\r\n",
    "              }"
   ],
   "outputs": [],
   "metadata": {
    "id": "vJ8zWJoB7PA9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create Grid Search\r\n",
    "grid = GridSearchCV(estimator = base_model,\r\n",
    "                    param_grid = param_grid, \r\n",
    "                    n_jobs=-2, \r\n",
    "                    verbose=1, \r\n",
    "                    cv=3)\r\n",
    "grid_result = grid.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Report Results\r\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dzihfCv-IRC",
    "outputId": "b98811cf-61b4-4dc2-80d8-4521bb3658d6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign the best model \r\n",
    "best_nn_model = grid_result.best_estimator_\r\n",
    "# Confirm the models params\r\n",
    "best_nn_model.get_params()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8gyYa85EZJe",
    "outputId": "f8515294-13cc-4c34-aa77-ba9f5a740c86"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "    best_nn_model.fit(X_train, \r\n",
    "                        y_train, \r\n",
    "                        validation_data = (X_val,y_val),\r\n",
    "                        verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check NN score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_nn_model_val_score = best_nn_model.score(X_val,y_val)\r\n",
    "print(\"The best NN model validation score is:\", best_nn_model_val_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create A Classifier Model \r\n",
    "Compare this model with our NN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf_model = make_pipeline(\r\n",
    "        RandomForestClassifier(\r\n",
    "        random_state = 42))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform Gridsearch to Optimize Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define the grid search parameters\r\n",
    "param_grid = {\r\n",
    "            \"randomforestclassifier__max_depth\": range(5,40,5),\r\n",
    "            \"randomforestclassifier__n_estimators\": range(25,125,25),\r\n",
    "            \"randomforestclassifier__max_features\": [\"auto\", \"sqrt\", \"log2\"]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid = GridSearchCV(estimator = clf_model,\r\n",
    "                    param_grid = param_grid, \r\n",
    "                    n_jobs = -2, \r\n",
    "                    verbose = 1, \r\n",
    "                    cv = 3)\r\n",
    "\r\n",
    "grid_result = grid.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Report Results\r\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign the best model \r\n",
    "best_clf_model = grid_result.best_estimator_\r\n",
    "# Confirm the models params\r\n",
    "best_clf_model.get_params()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check the CLF score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_clf_model_val_score = best_clf_model.score(X_val,y_val)\r\n",
    "print(\"The best CLF model validation score is:\", best_clf_model_val_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Logistic Regressor Model \r\n",
    "Compare this model with our NN and CLF Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "lr_model = make_pipeline(\r\n",
    "        LogisticRegression(\r\n",
    "        random_state = 42))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimize Logistic Regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# define the grid search parameters\r\n",
    "param_grid = {\r\n",
    "            \"logisticregression__solver\": [\"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "grid = GridSearchCV(estimator = lr_model,\r\n",
    "                    param_grid = param_grid, \r\n",
    "                    n_jobs = -2, \r\n",
    "                    verbose = 1, \r\n",
    "                    cv = 3)\r\n",
    "\r\n",
    "grid_result = grid.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Report Results\r\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.7182756527018822 using {'logisticregression__solver': 'lbfgs'}\n",
      "Means: 0.7182756527018822, Stdev: 0.010551394776552982 with: {'logisticregression__solver': 'lbfgs'}\n",
      "Means: 0.7170613236187006, Stdev: 0.009705141082662915 with: {'logisticregression__solver': 'liblinear'}\n",
      "Means: 0.310261080752884, Stdev: 0.00085866032930973 with: {'logisticregression__solver': 'sag'}\n",
      "Means: 0.310261080752884, Stdev: 0.00085866032930973 with: {'logisticregression__solver': 'saga'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Assign the best model \r\n",
    "best_lr_model = grid_result.best_estimator_\r\n",
    "# Confirm the models params\r\n",
    "best_lr_model.get_params()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('logisticregression', LogisticRegression(random_state=42))],\n",
       " 'verbose': False,\n",
       " 'logisticregression': LogisticRegression(random_state=42),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "best_lr_model_val_score = best_lr_model.score(X_val,y_val)\r\n",
    "print(\"The best lr model validation score is:\", best_lr_model_val_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The best lr model validation score is: 0.7404371584699454\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Model Scores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print(\"The best NN model validation score is:\", best_nn_model_val_score)\r\n",
    "print(\"The best CLF model validation score is:\", best_clf_model_val_score)\r\n",
    "print(\"The best lr model validation score is:\", best_lr_model_val_score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The best NN model validation score is: 0.9098360538482666\n",
      "The best CLF model validation score is: 0.9426229508196722\n",
      "The best lr model validation score is: 0.7404371584699454\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO Compare Precision and Recall with Confusion Matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explore The Best Model's Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO Create Feature importance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO Visualize Feature Importances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO Create Shapley"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save The Best Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import joblib\r\n",
    "joblib.dump(#TODO Insert best model here, \"my_h5_model.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Save the entire model as a SavedModel.\r\n",
    "# !mkdir -p saved_model\r\n",
    "# clf_model.save('my_h5_model.h5') "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko0g_byzFtVW",
    "outputId": "35da2382-7851-4ada-96f2-98d6744dacb0"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kickstarter EDA.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b6aa737f36c5d93b6cbe8b742cd1c1391a187201e6ed0bc134578f07fcbe3de9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}